peer.discovery = {

    # if peer discovery is off
    # the peer window will show
    # only what retrieved by active
    # peer [true/false]
    enabled = false

    # number of workers that
    # tastes the peers for being
    # online [1..10]
    workers = 8

    # List of the peers to start
    # the search of the online peers
    # values: [ip:port, ip:port, ip:port ...]
    ip.list = [
    ]

    # indicates if the discovered nodes and their reputations
    # are stored in DB and persisted between VM restarts
    persist = true

    # the period in seconds with which the discovery
    # tries to reconnect to successful nodes
    # 0 means the nodes are not reconnected
    touchPeriod = 600

    # the maximum nuber of nodes to reconnect to
    # -1 for unlimited
    touchMaxNodes = 100

    # external IP/hostname which is reported as our host during discovery
    # if not set, the service http://checkip.amazonaws.com is used
    # the last resort is to get the peer.bind.ip address
    #external.ip = null

    # Local network adapter IP to which
    # the discovery UDP socket is bound
    # e.g: 192.168.1.104
    #
    # if the value is empty will be retrived
    # by punching to some know address e.g: www.google.com
    #bind.ip = ""

    # indicates whether the discovery will include own home node
    # within the list of neighbor nodes
    public.home.node = true
}

peer {

        # Boot node list
        active = [
          { url = "enode://26ba1aadaf59d7607ad7f437146927d79e80312f026cfa635c6b2ccf2c5d3521f5812ca2beb3b295b14f97110e6448c1c7ff68f14c5328d43a3c62b44143e9b1@localhost:30304" },
          { url = "enode://b44eac67bdb83609c793c6eaf3555e4ff0ab39887ef5696255d813a6a47b51727545360daa6169add9b927599d942db017212094c17083b243b7a6553dd161ca@localhost:30310" }
        ]

        # list of trusted peers the incoming connections is always accepted from
        trusted = [
        ]

        # The protocols supported by peer
        # can be: [eth, shh, bzz]
        capabilities = [eth]

        # Peer for server to listen for incoming
        # connections
        listen.port = 30303

        # connection timeout for trying to connect to a peer [seconds]
        connection.timeout = 2

        # the parameter specifies how much
        # time we will wait for a message
        # to come before closing the channel
        channel.read.timeout = 90

        # Private key of the peer
        # The key is generated by default on the first run and stored in the database folder
        # If you have your own peer ID specify its private key here
        privateKey = 3ec771c31cac8c0dba77a69e503765701d3c2bb62435888d4ffa38fed60c445c

        # Network id
        networkId = 161

        #p2p {

        #}

        # max number of active peers our node will maintain
        # extra peers trying to connect us will be dropeed with TOO_MANY_PEERS message
        # the incoming connection from the peer matching 'peer.trusted' entry is always accepted
        maxAcivePeers = 30
    }

# the folder resources/genesis contains the genesis configuration according to the network the peer will run on
genesis = sample-genesis.json

# Blockchain settings (constants and algorithms) which are
# not described in the genesis file (like MINIMUM_DIFFICULTY or Mining algorithm)
# The possible named presets are:
# - main : the main network (Frontier-Homestead-...)
# - morden: Morden test network
# - testnet: Ethercamp test network
# - olympic: pre-Frontier Olympic network

blockchain.config.name = "testnet"



# the time we wait to the network to approve the transaction
transaction.approve.timeout = 15

# the number of blocks that should pass before pending transaction is removed
transaction.outdated.threshold = 10


database {
    # place to save physical storage files can be either absolute or relative path
    dir = database-transactor

    # every time the application starts the existing database will be destroyed and all the data will be downloaded from peers again [true/false]
    reset = false
}

# this string is computed to be eventually the address that get the miner reward
coinbase.secret = monkey

dump {
    # for testing purposes all the state will be dumped in JSON form to [dump.dir]
    # if [dump.full] = true
    # possible values [true/false]
    full = false
    dir = dmp

    # This defines the vmtrace dump to the console and the style
    # -1 for no block trace
    # styles: [pretty/standard+] (default: standard+)
    block = -1
    style = pretty

    # clean the dump dir each start
    clean.on.restart = true
}

# structured trace is the trace being collected in the form of objects and exposed to the user in json or any other convenient form.
vm.structured {
    trace = false
    dir = vmtrace
    compressed = true
    initStorageLimit = 10000
}

# make changes to tracing options starting from certain block
# -1 don't make any tracing changes
trace.startblock = -1

# invoke vm program on message received,
# if the vm is not invoked the balance transfer occurs anyway  [true/false]
play.vm = true

# hello phrase will be included in the hello message of the peer
#hello.phrase = Dev

# this property used
# mostly for a debug purpose
# so if you don't know exactly how
# to apply it leave to be [-1]
#
# ADVANCED: if we want to load a root hash
# for db not from the saved block chain (last block)
# but any manual hash this property will help.
# values [-1] - load from db
#        [hex hash 32 bytes] root hash
#root.hash.start = null

# Key value data source values: [leveldb/redis/mapdb]
keyvalue.datasource = leveldb

# Redis cloud enabled flag.
# Allows using RedisConnection for creating cloud based data structures.
redis.enabled=false

record.blocks=false
blockchain.only=false

# Load the blocks
# from a rlp lines
# file and not for
# the net
blocks.loader=""


# the parameter to specify when exactly to switch managing storage of the account on autonomous db
# the limit is specified in contract storage bytes
details.inmemory.storage.limit=1000000

# cache for blockchain run the flush happens depending on memory usage or blocks treshhold
# if both specipied memory will take precedence
cache {

    flush {

        # [0.7 = 70% memory to flush]
        memory = 0

        # [10000 flush each 10000 blocks]
        blocks = 1000
    }
}

# eth sync process
sync {

        # block chain synchronization
        # can be: [true/false]
        enabled = true

        # maximum blocks hashes to ask.
        # sending GET_BLOCK_HASHES msg
        # we specify number of block we want to get, recommended value [1..1000]
        # Default: unlimited
        max.hashes.ask = 10000

        # maximum blocks to ask,
        # when downloading the chain sequenteally sending GET_BLOCKS msg
        # we specify number of blocks we want to get, recomendec value [1..120]
        max.blocks.ask = 100

        # minimal peers count used in sync process
        # sync may use more peers than this value but always trying to get at least this number from discovery
        peer.count = 30

        # Uncomment this param to use a strict Eth version.
        # Useful for testing
        version = 62
}

# miner options
mine {

    # start mining blocks
    # when 'sync.enabled' is true the mining starts when the sync is complete
    # else the mining will start immediately taking the best block from database
    # (or genesis if no blocks exist yet)
    start = false

    # mining beneficiary
    coinbase = "50b8f981ce93fd5b81b844409169148428400bf3"

    # extra data included to the mined block
    # one of two properties should be specified
    extraData = "EthereumJ powered"
    #extraDataHex = "0102abcd"

    # transactions with the gas price lower than this will not be
    # included to minled blocks
    # decimal number in weis
    minGasPrice = 0  # 50 Gwei

    # minimal timeout between mined blocks
    minBlockTimeoutMsec = 0

    # number of CPU threads the miner will mine on
    # 0 disables CPU mining
    cpuMineThreads = 4

    # there two options for CPU mining 'light' and 'full'
    # 'light' requires only 16M of RAM but is much slower
    # 'full' requires 1G of RAM and possibly ~7min for the DataSet generation
    #   but is much faster during mining
    fullDataSet = true
}